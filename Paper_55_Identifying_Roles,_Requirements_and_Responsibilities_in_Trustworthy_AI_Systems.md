# Paper 54:

## Paper Title: Identifying Roles, Requirements and Responsibilities in Trustworthy AI Systems

## Authors:
Iain Barclay and Will Abramson

## Publication Year:
2021

## Source/Conference/Journal:
UbiComp-ISWC ’21 Adjunct, September 21–26, 2021, Virtual, USA

## Abstract/Introduction Summary:
The paper discusses the roles and responsibilities of various actors in the ecosystem of AI systems, with a focus on Domain Practitioners (DPs), Systems Integrators (SIs), Machine Learning Engineers (MLEs), and Data Scientists (DSs). It highlights the tensions between the desire for transparency and the need for confidentiality in sharing information among these actors. The paper introduces a framework for understanding the sociotechnological structure of data-driven AI systems from the perspective of DPs and discusses the requirements and responsibilities of each role in ensuring the trustworthiness of AI systems.

## Motivation:
The motivation for this paper stems from the need to address the challenges of deploying AI systems in critical domains like healthcare and education. Domain practitioners often lack insight into the data and processes underlying these systems, and this paper aims to help them intelligently assess whether an AI system is suitable for their domain.

## Tools:
The paper mentions tools indirectly related to AI system development and deployment, such as data collection and preparation tools, but it doesn't explicitly name specific tools.

## Benefits:
- Provides a framework for understanding the sociotechnological structure of AI systems.
- Clarifies roles and responsibilities of actors in the AI system ecosystem.
- Highlights the need for transparency and accountability in AI system development.

## Metrics:
The paper doesn't introduce specific metrics but discusses the need for transparency and accountability in AI system development.

## Approaches:
- Introduces an actor-based framework to visualize roles and dependencies in AI systems.
- Discusses the tension between transparency and confidentiality in sharing information among actors.

## Challenges:
- Balancing the need for transparency with privacy and confidentiality concerns.
- Ensuring that AI systems meet domain-specific requirements.

## How to implement responsible AI methods:
The paper doesn't provide a detailed guide on implementing responsible AI methods but emphasizes the importance of transparency, accountability, and information sharing among actors.

## Reviewer's Comments:
This paper provides valuable insights into the roles and responsibilities of actors involved in AI systems, particularly from the perspective of domain practitioners. It highlights the challenges and tensions in sharing information while ensuring trustworthiness. However, it could benefit from more concrete examples and practical recommendations for implementing responsible AI methods.

## A 400-word pitch for the paper:
"Identifying Roles, Requirements, and Responsibilities in Trustworthy AI Systems" offers a comprehensive exploration of the intricate ecosystem surrounding AI system development and deployment. Authored by Iain Barclay and Will Abramson, this paper dives deep into the roles played by various actors, from Domain Practitioners to Machine Learning Engineers, shedding light on their responsibilities and dependencies.

In today's world, AI systems are making significant inroads into critical domains such as healthcare and education. However, the lack of transparency and understanding surrounding these systems can pose significant challenges. This paper recognizes the critical need for domain practitioners to make informed decisions about AI system adoption. It empowers them with knowledge about the data and processes behind AI systems, thus ensuring they can intelligently assess whether a particular AI system is appropriate for their specific domain.

The paper introduces a novel actor-based framework that provides a visual representation of the roles and dependencies within AI systems. It emphasizes the importance of transparency and accountability, highlighting the tensions that arise between these principles and the imperative to protect sensitive information. This framework not only clarifies the roles and responsibilities but also identifies the trust frontiers where information flow is crucial.

One of the paper's significant benefits is its emphasis on the need for transparency and accountability. It underscores the responsibility of those involved in AI system development to provide domain practitioners with trustworthy information. The paper recognizes that while complete transparency may not always be feasible or desirable due to privacy and confidentiality concerns, there is a vital need to verify specific claims about AI systems.

Despite its many merits, the paper could benefit from more concrete examples and practical recommendations for implementing responsible AI methods. Nonetheless, its comprehensive exploration of the roles, responsibilities, and dependencies within the AI system ecosystem makes it a valuable resource for anyone involved in AI system development and deployment.

In conclusion, "Identifying Roles, Requirements, and Responsibilities in Trustworthy AI Systems" is a seminal work that addresses a pressing issue in the AI field. It offers a robust framework and valuable insights for navigating the complexities of AI system development while ensuring transparency, accountability, and trustworthiness."
